{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa683097-2d7c-4fd2-9f5b-dcae8098cac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Machine', 'learning'), ('learning', 'is'), ('is', 'an'), ('an', 'important'), ('important', 'part'), ('part', 'of'), ('of', 'AIand'), ('AIand', 'AI'), ('AI', 'is'), ('is', 'going'), ('going', 'to'), ('to', 'become'), ('become', 'inmportant'), ('inmportant', 'for'), ('for', 'daily'), ('daily', 'functionong')]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.util import ngrams\n",
    "s=\"Machine learning is an important part of AI\"\"and AI is going to become inmportant for daily functionong\" \n",
    "tokens=[token for token in s.split(\" \")]\n",
    "output=list(ngrams(tokens,2))\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "483136e1-6aa2-4fb6-b41d-9583b4d06d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BBDO South', 'Georgia-Pacific']\n"
     ]
    }
   ],
   "source": [
    "locs = [('Omnicom', 'IN', 'New York'),('DDB Needham', 'IN', 'New York'),('Kaplan Thaler Group', 'IN', 'New York'), ('BBDO South', 'IN', 'Atlanta'),('Georgia-Pacific', 'IN', 'Atlanta')]\n",
    "query = [e1 for (e1, rel, e2) in locs if e2=='Atlanta']\n",
    "print(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d8fa30e-453f-4032-b7ef-57ead7254837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData():\n",
    "    data = ['This is a dog', 'This is a cat', 'I love my cat', 'This is my name']\n",
    "    dat = []\n",
    "    for i in range(len(data)):\n",
    "        for word in data[i].split():\n",
    "            dat.append(word)\n",
    "    print(dat)\n",
    "    return dat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87f64769-2378-45fe-8a2d-0af03e2b4098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBigram(data):\n",
    "    listOfBigrams = []\n",
    "    bigramCounts = {}\n",
    "    unigramCounts = {}\n",
    "    for i in range(len(data)-1):\n",
    "      if i <len(data)-1 and data[i+1].islower():\n",
    "          listOfBigrams.append((data[i],data[i+1]))\n",
    "          if(data[i],data[i+1]) in bigramCounts:\n",
    "            bigramCounts[(data[i],data[i+1])] += 1\n",
    "          else:\n",
    "            bigramCounts[(data[i],data[i+1])] = 1\n",
    "      if data[i] in unigramCounts:\n",
    "            unigramCounts[data[i]] += 1\n",
    "      else:\n",
    "            unigramCounts[data[i]] = 1\n",
    "    return listOfBigrams, unigramCounts, bigramCounts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c8a8b38-bd1b-4697-bc23-de568528b0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'dog', 'This', 'is', 'a', 'cat', 'I', 'love', 'my', 'cat', 'This', 'is', 'my', 'name']\n",
      "\n",
      " All the possible Bigrams are \n",
      "[('This', 'is'), ('is', 'a'), ('a', 'dog'), ('This', 'is'), ('is', 'a'), ('a', 'cat'), ('I', 'love'), ('love', 'my'), ('my', 'cat'), ('This', 'is'), ('is', 'my'), ('my', 'name')]\n",
      "\n",
      " Bigrams along with their frequency \n",
      "{('This', 'is'): 3, ('is', 'a'): 2, ('a', 'dog'): 1, ('a', 'cat'): 1, ('I', 'love'): 1, ('love', 'my'): 1, ('my', 'cat'): 1, ('is', 'my'): 1, ('my', 'name'): 1}\n",
      "\n",
      " Unigrams along with their frequency \n",
      "{'This': 3, 'is': 3, 'a': 2, 'dog': 1, 'cat': 2, 'I': 1, 'love': 1, 'my': 2}\n",
      "\n",
      " Bigrams along with their probability\n",
      "{('This', 'is'): 1.0, ('is', 'a'): 0.6666666666666666, ('a', 'dog'): 0.5, ('a', 'cat'): 0.5, ('I', 'love'): 1.0, ('love', 'my'): 1.0, ('my', 'cat'): 0.5, ('is', 'my'): 0.3333333333333333, ('my', 'name'): 0.5}\n",
      "\n",
      " The bigrams in given sentence are\n",
      "[('This', 'is'), ('is', 'my'), ('my', 'cat')]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'float' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(bilist)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(bilist)):\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bilist[i] \u001b[38;5;129;01min\u001b[39;00m bigramProb[bilist[i]]:\n\u001b[0;32m     34\u001b[0m         outoutProb1 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m bigramProb[bilist[i]]\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'float' is not iterable"
     ]
    }
   ],
   "source": [
    "def calcBigramProb(listOfBigrams, unigramCounts, bigramCounts):\n",
    "    listOfProb = {}\n",
    "    for bigram in listOfBigrams:\n",
    "        word1= bigram[0]\n",
    "        word2= bigram[1]\n",
    "        listOfProb[bigram] = (bigramCounts.get(bigram)) /(unigramCounts.get(word1))\n",
    "    return listOfProb\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data=readData()\n",
    "    listOfBigrams, unigramCounts, bigramCounts=createBigram(data)\n",
    "    \n",
    "    print(\"\\n All the possible Bigrams are \")\n",
    "    print(listOfBigrams)\n",
    "    print(\"\\n Bigrams along with their frequency \")\n",
    "    print(bigramCounts)\n",
    "    print(\"\\n Unigrams along with their frequency \")\n",
    "    print(unigramCounts)\n",
    "    bigramProb=calcBigramProb(listOfBigrams, unigramCounts, bigramCounts)\n",
    "    print(\"\\n Bigrams along with their probability\")\n",
    "    print(bigramProb)\n",
    "    inputList=\"This is my cat\"\n",
    "    splt=inputList.split()\n",
    "    outputProb1= 1\n",
    "    bilist= []\n",
    "    bigrm =[]\n",
    "    for i in range (len(splt) - 1):\n",
    "        if i < len(splt) - 1:\n",
    "            bilist.append((splt[i], splt[i+1]))\n",
    "    print(\"\\n The bigrams in given sentence are\")\n",
    "    print(bilist)\n",
    "    for i in range(len(bilist)):\n",
    "        if bilist[i] in bigramProb[bilist[i]]:\n",
    "            outoutProb1 *= bigramProb[bilist[i]]\n",
    "        else:\n",
    "            outoutProb1 *= 0\n",
    "    print('\\n' + 'Probability of sentence \\\"This is my cat\\\" ='+str(outputProb1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e45738e-5828-47e8-a786-fd3dbb1adc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
