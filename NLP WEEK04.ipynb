{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6057a282-5f21-4f40-b263-194d32617244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities: ['Indian', 'Institute', 'Technology', 'IIT']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\tkrcet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\tkrcet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "# Sample text\n",
    "text = \"I visited the Indian Institute of Technology (IIT) last summer.\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "# Part-of-speech tagging\n",
    "tagged_tokens = nltk.pos_tag(tokens)\n",
    "\n",
    "# Named Entity Recognition (NER)\n",
    "named_entities = nltk.ne_chunk(tagged_tokens)\n",
    "\n",
    "# Extracting named entities\n",
    "entities = []\n",
    "for entity in named_entities:\n",
    "    if isinstance(entity, nltk.Tree):\n",
    "        entities.append(\" \".join([word for word, tag in entity.leaves()]))\n",
    "\n",
    "print(\"Named Entities:\", entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35bdafbd-5e54-40ea-918a-32fb51d040c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Extracting the parts\n",
      "\n",
      " (S\n",
      "  (NP This/DT tree/NN)\n",
      "  (VP (V is/VBZ))\n",
      "  (VP\n",
      "    (V illustrating/VBG)\n",
      "    (NP the/DT constituency/NN)\n",
      "    (NP relation/NN))) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize, RegexpParser\n",
    "\n",
    "# String to parse\n",
    "to_parse = \"This tree is illustrating the constituency relation\"\n",
    "\n",
    "# Find all parts of speech in above sentence\n",
    "tagged_parts = pos_tag(word_tokenize(to_parse))\n",
    "\n",
    "# Defining grammar on basis of which we 've to extract\n",
    "grammar = r\"\"\"\n",
    "    NP: {<DT>?<JJ>*<NN>}\n",
    "    P: {<IN>}\n",
    "    V: {<V.*>}\n",
    "    PP: {<p> <NP>}\n",
    "    VP: {<V> <NP|PP>*}\"\"\"\n",
    "\n",
    "# Extracting all parts of speech\n",
    "parser = RegexpParser(grammar)\n",
    "\n",
    "# Print all parts of speech in above sentence\n",
    "output = parser.parse(tagged_parts)\n",
    "print(\"\\nAfter Extracting the parts\\n\\n\", output,\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04cc0095-989d-478a-a35d-2e3efdf80b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Mary\n",
      "Verb: likes\n",
      "Object: Mary\n"
     ]
    }
   ],
   "source": [
    "def extract_semantic_info(sentence):\n",
    "    words = sentence.split()\n",
    "    subject = \"\"\n",
    "    verb = \"\"\n",
    "    object_ = \"\"\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        if words[i].lower() in [\"he\", \"she\", \"it\", \"they\", \"john\", \"mary\"]:\n",
    "            subject = words[i]\n",
    "        elif words[i].lower() in [\"likes\", \"loves\", \"hates\", \"adores\"]:\n",
    "            verb = words[i]\n",
    "        if i+1 < len(words):\n",
    "            object_=words[i+1]\n",
    "\n",
    "    return subject, verb, object_\n",
    "\n",
    "# Sample sentence\n",
    "sentence = \"John likes Mary\"\n",
    "\n",
    "# Extract semantic information\n",
    "subject, verb, object_ = extract_semantic_info(sentence)\n",
    "\n",
    "# Print semantic information\n",
    "print(\"Subject:\", subject)\n",
    "print(\"Verb:\", verb)\n",
    "print(\"Object:\", object_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
